import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from groq import Groq
import openai
import google.generativeai as genai
import os
from io import StringIO
from scipy import stats
from sklearn.preprocessing import StandardScaler
import warnings
warnings.filterwarnings('ignore')

# Configura√ß√£o da p√°gina
st.set_page_config(
    page_title="Agente de An√°lise de Dados CSV - Melhorado",
    page_icon="üìä",
    layout="wide"
)

# Configurar estilo matplotlib para alto contraste
plt.style.use('dark_background')

# Fun√ß√£o para inicializar o hist√≥rico de conversa√ß√£o
def init_conversation_history():
    if 'conversation_history' not in st.session_state:
        st.session_state.conversation_history = []
    if 'data_context' not in st.session_state:
        st.session_state.data_context = None

# Fun√ß√£o para adicionar mensagem ao hist√≥rico
def add_to_conversation(role, content):
    st.session_state.conversation_history.append({"role": role, "content": content})

# Fun√ß√£o para preparar contexto completo dos dados
def prepare_data_context(data):
    numeric_cols = data.select_dtypes(include=[np.number]).columns.tolist()
    categorical_cols = data.select_dtypes(include=['object', 'category']).columns.tolist()
    
    context = {
        'shape': data.shape,
        'columns': data.columns.tolist(),
        'dtypes': data.dtypes.to_dict(),
        'numeric_columns': numeric_cols,
        'categorical_columns': categorical_cols,
        'missing_values': data.isnull().sum().to_dict(),
        'basic_stats': data.describe().to_dict() if numeric_cols else {},
        'categorical_stats': {col: data[col].value_counts().head(10).to_dict() for col in categorical_cols},
        'sample_data': data.head(5).to_dict('records')
    }
    return context

# Fun√ß√£o para chamar diferentes APIs
def call_ai_api(api_choice, api_key, messages, model=None):
    try:
        if api_choice == "OpenAI":
            client = openai.OpenAI(api_key=api_key)
            response = client.chat.completions.create(
                model=model or "gpt-3.5-turbo",
                messages=messages,
                max_tokens=2000,
                temperature=0.7
            )
            return response.choices[0].message.content
            
        elif api_choice == "Groq":
            client = Groq(api_key=api_key)
            response = client.chat.completions.create(
                model=model or "llama-3.3-70b-versatile",
                messages=messages,
                max_tokens=2000,
                temperature=0.7
            )
            return response.choices[0].message.content
            
        elif api_choice == "Gemini":
            genai.configure(api_key=api_key)
            model_instance = genai.GenerativeModel(model or 'gemini-pro')
            
            # Converter mensagens para formato do Gemini
            prompt = ""
            for msg in messages:
                if msg["role"] == "system":
                    prompt += f"Instru√ß√µes: {msg['content']}\n\n"
                elif msg["role"] == "user":
                    prompt += f"Usu√°rio: {msg['content']}\n\n"
                elif msg["role"] == "assistant":
                    prompt += f"Assistente: {msg['content']}\n\n"
            
            response = model_instance.generate_content(prompt)
            return response.text
            
    except Exception as e:
        return f"Erro ao chamar a API: {str(e)}"

# Fun√ß√£o para criar gr√°ficos de distribui√ß√£o melhorados
def create_distribution_plots(data, numeric_cols, categorical_cols):
    plots_created = []
    
    # Gr√°ficos para vari√°veis num√©ricas
    if numeric_cols:
        st.subheader("üìä Distribui√ß√µes - Vari√°veis Num√©ricas")
        
        # Calcular n√∫mero de colunas e linhas para o grid
        n_cols = len(numeric_cols)
        cols_per_row = 3
        rows = (n_cols + cols_per_row - 1) // cols_per_row
        
        fig, axes = plt.subplots(rows, cols_per_row, figsize=(18, 6*rows))
        fig.patch.set_facecolor('#0E1117')
        
        # Garantir que axes seja sempre um array 2D
        if rows == 1:
            if cols_per_row == 1:
                axes = np.array([[axes]])
            else:
                axes = axes.reshape(1, -1)
        elif cols_per_row == 1:
            axes = axes.reshape(-1, 1)
        
        for i, col in enumerate(numeric_cols):
            row = i // cols_per_row
            col_idx = i % cols_per_row
            ax = axes[row, col_idx]
            
            # Criar histograma com densidade
            data[col].hist(ax=ax, bins=30, alpha=0.7, color='cyan', density=True, edgecolor='white')
            
            # Adicionar curva de densidade
            try:
                data_clean = data[col].dropna()
                if len(data_clean) > 1:
                    kde = stats.gaussian_kde(data_clean)
                    x_range = np.linspace(data_clean.min(), data_clean.max(), 100)
                    ax.plot(x_range, kde(x_range), color='orange', linewidth=2, label='Densidade')
                    ax.legend()
            except:
                pass
            
            ax.set_title(f'Distribui√ß√£o: {col}', color='white', fontsize=12, pad=10)
            ax.set_xlabel(col, color='white')
            ax.set_ylabel('Densidade', color='white')
            ax.set_facecolor('#0E1117')
            ax.tick_params(colors='white')
            ax.grid(True, alpha=0.3)
        
        # Remover subplots vazios
        for i in range(n_cols, rows * cols_per_row):
            row = i // cols_per_row
            col_idx = i % cols_per_row
            fig.delaxes(axes[row, col_idx])
        
        plt.tight_layout()
        st.pyplot(fig)
        plt.close()
        plots_created.append("Distribui√ß√µes num√©ricas")
    
    # Gr√°ficos para vari√°veis categ√≥ricas
    if categorical_cols:
        st.subheader("üìä Distribui√ß√µes - Vari√°veis Categ√≥ricas")
        
        for col in categorical_cols:
            value_counts = data[col].value_counts().head(15)  # Top 15 valores
            
            fig, ax = plt.subplots(figsize=(12, 8))
            fig.patch.set_facecolor('#0E1117')
            
            bars = ax.bar(range(len(value_counts)), value_counts.values, 
                         color='lightcoral', alpha=0.8, edgecolor='white')
            
            ax.set_title(f'Distribui√ß√£o: {col}', color='white', fontsize=16, pad=20)
            ax.set_xticks(range(len(value_counts)))
            ax.set_xticklabels(value_counts.index, rotation=45, ha='right', color='white')
            ax.set_ylabel('Frequ√™ncia', color='white')
            ax.set_facecolor('#0E1117')
            ax.tick_params(colors='white')
            ax.grid(True, alpha=0.3, axis='y')
            
            # Adicionar valores nas barras
            for bar, value in zip(bars, value_counts.values):
                height = bar.get_height()
                ax.text(bar.get_x() + bar.get_width()/2, height + max(value_counts.values)*0.01,
                       f'{value:,}', ha='center', va='bottom', color='white', fontsize=10)
            
            plt.tight_layout()
            st.pyplot(fig)
            plt.close()
            plots_created.append(f"Distribui√ß√£o categ√≥rica: {col}")
    
    return plots_created

# Fun√ß√£o para an√°lise de tend√™ncias melhorada
def create_trend_analysis(data, numeric_cols, categorical_cols):
    st.header("üìà An√°lise de Tend√™ncias Melhorada")
    
    # Detectar colunas temporais
    time_cols = []
    for col in data.columns:
        if any(keyword in col.lower() for keyword in ['time', 'date', 'timestamp', 'year', 'month', 'day']):
            time_cols.append(col)
    
    if time_cols and numeric_cols:
        st.subheader("üìÖ Tend√™ncias Temporais")
        
        col1, col2 = st.columns(2)
        with col1:
            time_col = st.selectbox("Selecione a coluna temporal:", time_cols)
        with col2:
            numeric_col = st.selectbox("Selecione a vari√°vel num√©rica:", numeric_cols)
        
        if time_col and numeric_col:
            fig, ax = plt.subplots(figsize=(14, 8))
            fig.patch.set_facecolor('#0E1117')
            
            # Ordenar dados por tempo
            data_sorted = data.sort_values(time_col).copy()
            x_values = range(len(data_sorted))
            y_values = data_sorted[numeric_col]
            
            # Plotar dados originais
            ax.scatter(x_values, y_values, alpha=0.6, color='cyan', s=20, label='Dados')
            
            # Adicionar linha de tend√™ncia
            try:
                # Remover valores nulos
                mask = ~(pd.isna(y_values))
                x_clean = np.array(x_values)[mask]
                y_clean = np.array(y_values)[mask]
                
                if len(x_clean) > 1:
                    # Calcular linha de tend√™ncia
                    z = np.polyfit(x_clean, y_clean, 1)
                    p = np.poly1d(z)
                    ax.plot(x_clean, p(x_clean), "r--", alpha=0.8, linewidth=2, label=f'Tend√™ncia (slope: {z[0]:.4f})')
                    
                    # Adicionar m√©dia m√≥vel
                    if len(y_clean) > 10:
                        window = min(20, len(y_clean) // 5)
                        moving_avg = pd.Series(y_clean).rolling(window=window, center=True).mean()
                        ax.plot(x_clean, moving_avg, color='orange', linewidth=2, alpha=0.8, label=f'M√©dia M√≥vel ({window})')
            except Exception as e:
                st.warning(f"N√£o foi poss√≠vel calcular a linha de tend√™ncia: {e}")
            
            ax.set_title(f'Tend√™ncia Temporal: {numeric_col} vs {time_col}', color='white', fontsize=16, pad=20)
            ax.set_xlabel('√çndice Temporal', color='white')
            ax.set_ylabel(numeric_col, color='white')
            ax.set_facecolor('#0E1117')
            ax.tick_params(colors='white')
            ax.grid(True, alpha=0.3)
            ax.legend()
            
            plt.tight_layout()
            st.pyplot(fig)
            plt.close()
    
    # An√°lise de correla√ß√£o temporal para vari√°veis num√©ricas
    if len(numeric_cols) > 1:
        st.subheader("üîÑ Correla√ß√µes e Tend√™ncias entre Vari√°veis")
        
        # Matriz de correla√ß√£o
        corr_matrix = data[numeric_cols].corr()
        
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))
        fig.patch.set_facecolor('#0E1117')
        
        # Heatmap de correla√ß√£o
        sns.heatmap(corr_matrix, annot=True, cmap='RdYlBu_r', center=0,
                   square=True, fmt='.2f', cbar_kws={'shrink': 0.8}, ax=ax1)
        ax1.set_title('Matriz de Correla√ß√£o', color='white', fontsize=14)
        ax1.set_facecolor('#0E1117')
        
        # Scatter plot das duas vari√°veis mais correlacionadas
        if len(numeric_cols) >= 2:
            # Encontrar a correla√ß√£o mais forte (excluindo diagonal)
            corr_abs = corr_matrix.abs()
            np.fill_diagonal(corr_abs.values, 0)
            max_corr_idx = np.unravel_index(corr_abs.values.argmax(), corr_abs.shape)
            var1, var2 = corr_matrix.columns[max_corr_idx[0]], corr_matrix.columns[max_corr_idx[1]]
            corr_value = corr_matrix.loc[var1, var2]
            
            ax2.scatter(data[var1], data[var2], alpha=0.6, color='lightgreen', s=30)
            
            # Adicionar linha de regress√£o
            try:
                mask = ~(pd.isna(data[var1]) | pd.isna(data[var2]))
                if mask.sum() > 1:
                    z = np.polyfit(data[var1][mask], data[var2][mask], 1)
                    p = np.poly1d(z)
                    x_range = np.linspace(data[var1].min(), data[var1].max(), 100)
                    ax2.plot(x_range, p(x_range), "r--", alpha=0.8, linewidth=2)
            except:
                pass
            
            ax2.set_title(f'Correla√ß√£o: {var1} vs {var2}\n(r = {corr_value:.3f})', color='white', fontsize=14)
            ax2.set_xlabel(var1, color='white')
            ax2.set_ylabel(var2, color='white')
            ax2.set_facecolor('#0E1117')
            ax2.tick_params(colors='white')
            ax2.grid(True, alpha=0.3)
        
        plt.tight_layout()
        st.pyplot(fig)
        plt.close()

# Fun√ß√£o para detec√ß√£o completa de outliers
def create_complete_outlier_analysis(data, numeric_cols):
    st.header("‚ö†Ô∏è An√°lise Completa de Outliers")
    
    if not numeric_cols:
        st.info("N√£o h√° vari√°veis num√©ricas para an√°lise de outliers.")
        return
    
    # Tabela resumo de outliers
    st.subheader("üìä Resumo de Outliers por Vari√°vel")
    
    outliers_summary = []
    outliers_data = {}
    
    for col in numeric_cols:
        Q1 = data[col].quantile(0.25)
        Q3 = data[col].quantile(0.75)
        IQR = Q3 - Q1
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR
        
        outliers = data[(data[col] < lower_bound) | (data[col] > upper_bound)]
        outliers_data[col] = outliers
        
        # Z-score outliers
        z_scores = np.abs(stats.zscore(data[col].dropna()))
        z_outliers = len(z_scores[z_scores > 3])
        
        outliers_summary.append({
            'Vari√°vel': col,
            'Outliers IQR': len(outliers),
            '% IQR': f"{(len(outliers) / len(data) * 100):.2f}%",
            'Outliers Z-score': z_outliers,
            '% Z-score': f"{(z_outliers / len(data) * 100):.2f}%",
            'Limite Inferior': f"{lower_bound:.2f}",
            'Limite Superior': f"{upper_bound:.2f}",
            'Min': f"{data[col].min():.2f}",
            'Max': f"{data[col].max():.2f}"
        })
    
    outliers_df = pd.DataFrame(outliers_summary)
    st.dataframe(outliers_df, use_container_width=True)
    
    # Visualiza√ß√µes completas de outliers
    st.subheader("üìà Visualiza√ß√µes de Outliers - Todos os Gr√°ficos")
    
    # Boxplots para todas as vari√°veis
    n_cols = len(numeric_cols)
    cols_per_row = 4
    rows = (n_cols + cols_per_row - 1) // cols_per_row
    
    fig, axes = plt.subplots(rows, cols_per_row, figsize=(20, 5*rows))
    fig.patch.set_facecolor('#0E1117')
    
    # Garantir que axes seja sempre um array 2D
    if rows == 1:
        if cols_per_row == 1:
            axes = np.array([[axes]])
        else:
            axes = axes.reshape(1, -1)
    elif cols_per_row == 1:
        axes = axes.reshape(-1, 1)
    
    for i, col in enumerate(numeric_cols):
        row = i // cols_per_row
        col_idx = i % cols_per_row
        ax = axes[row, col_idx]
        
        # Boxplot
        bp = ax.boxplot(data[col].dropna(), patch_artist=True, 
                       boxprops=dict(facecolor='lightblue', alpha=0.7),
                       medianprops=dict(color='red', linewidth=2),
                       whiskerprops=dict(color='white'),
                       capprops=dict(color='white'),
                       flierprops=dict(marker='o', markerfacecolor='red', markersize=4, alpha=0.7))
        
        ax.set_title(f'{col}', color='white', fontsize=12)
        ax.set_facecolor('#0E1117')
        ax.tick_params(colors='white')
        ax.grid(True, alpha=0.3)
        
        # Adicionar estat√≠sticas
        Q1 = data[col].quantile(0.25)
        Q3 = data[col].quantile(0.75)
        median = data[col].median()
        ax.text(0.02, 0.98, f'Q1: {Q1:.2f}\nMediana: {median:.2f}\nQ3: {Q3:.2f}', 
               transform=ax.transAxes, verticalalignment='top', 
               bbox=dict(boxstyle='round', facecolor='black', alpha=0.7),
               color='white', fontsize=8)
    
    # Remover subplots vazios
    for i in range(n_cols, rows * cols_per_row):
        row = i // cols_per_row
        col_idx = i % cols_per_row
        fig.delaxes(axes[row, col_idx])
    
    plt.tight_layout()
    st.pyplot(fig)
    plt.close()
    
    # Gr√°ficos de dispers√£o para identificar outliers multivariados
    if len(numeric_cols) >= 2:
        st.subheader("üéØ Outliers Multivariados - Scatter Plots")
        
        # Pegar as 4 vari√°veis com mais outliers
        top_outlier_vars = outliers_df.nlargest(4, 'Outliers IQR')['Vari√°vel'].tolist()
        
        if len(top_outlier_vars) >= 2:
            fig, axes = plt.subplots(2, 2, figsize=(16, 12))
            fig.patch.set_facecolor('#0E1117')
            
            combinations = [(top_outlier_vars[i], top_outlier_vars[j]) 
                          for i in range(len(top_outlier_vars)) 
                          for j in range(i+1, len(top_outlier_vars))][:4]
            
            for idx, (var1, var2) in enumerate(combinations):
                row = idx // 2
                col = idx % 2
                ax = axes[row, col]
                
                # Scatter plot normal
                ax.scatter(data[var1], data[var2], alpha=0.6, color='lightblue', s=30, label='Normal')
                
                # Destacar outliers
                outliers_var1 = outliers_data[var1]
                outliers_var2 = outliers_data[var2]
                
                if len(outliers_var1) > 0:
                    ax.scatter(outliers_var1[var1], outliers_var1[var2], 
                             color='red', s=50, alpha=0.8, label=f'Outliers {var1}')
                
                if len(outliers_var2) > 0:
                    ax.scatter(outliers_var2[var1], outliers_var2[var2], 
                             color='orange', s=50, alpha=0.8, label=f'Outliers {var2}')
                
                ax.set_title(f'{var1} vs {var2}', color='white', fontsize=12)
                ax.set_xlabel(var1, color='white')
                ax.set_ylabel(var2, color='white')
                ax.set_facecolor('#0E1117')
                ax.tick_params(colors='white')
                ax.grid(True, alpha=0.3)
                ax.legend()
            
            plt.tight_layout()
            st.pyplot(fig)
            plt.close()

# T√≠tulo principal
st.title("ü§ñ Agente de An√°lise Explorat√≥ria de Dados - VERS√ÉO MELHORADA")
st.markdown("**Ferramenta inteligente com mem√≥ria conversacional e m√∫ltiplas APIs de IA**")

# Inicializar hist√≥rico de conversa√ß√£o
init_conversation_history()

# Upload do arquivo
uploaded_file = st.file_uploader(
    "Carregue seu arquivo CSV para an√°lise", 
    type=['csv'],
    help="Selecione um arquivo CSV para realizar a an√°lise explorat√≥ria completa"
)

if uploaded_file is not None:
    # Carregar os dados
    try:
        data = pd.read_csv(uploaded_file)
        st.success(f"‚úÖ Arquivo carregado com sucesso! {data.shape[0]} linhas e {data.shape[1]} colunas.")
        
        # Preparar contexto dos dados para IA
        st.session_state.data_context = prepare_data_context(data)
        
        # Criar abas para organizar a an√°lise
        tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs([
            "üìã Vis√£o Geral", 
            "üìä Distribui√ß√µes", 
            "üîç Correla√ß√µes", 
            "üìà Tend√™ncias", 
            "‚ö†Ô∏è Anomalias", 
            "ü§ñ Chat com IA"
        ])
        
        # Separar vari√°veis num√©ricas e categ√≥ricas
        numeric_cols = data.select_dtypes(include=[np.number]).columns.tolist()
        categorical_cols = data.select_dtypes(include=['object', 'category']).columns.tolist()
        
        with tab1:
            st.header("üìã Vis√£o Geral dos Dados")
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.subheader("Informa√ß√µes B√°sicas")
                st.write(f"**N√∫mero de linhas:** {data.shape[0]:,}")
                st.write(f"**N√∫mero de colunas:** {data.shape[1]:,}")
                st.write(f"**Tamanho em mem√≥ria:** {data.memory_usage(deep=True).sum() / 1024**2:.2f} MB")
                st.write(f"**Vari√°veis num√©ricas:** {len(numeric_cols)}")
                st.write(f"**Vari√°veis categ√≥ricas:** {len(categorical_cols)}")
                
                st.subheader("Tipos de Dados")
                tipos_dados = pd.DataFrame({
                    'Coluna': data.dtypes.index,
                    'Tipo': data.dtypes.values.astype(str),
                    'Valores √önicos': [data[col].nunique() for col in data.columns],
                    'Valores Nulos': [data[col].isnull().sum() for col in data.columns],
                    '% Nulos': [f"{(data[col].isnull().sum() / len(data) * 100):.1f}%" for col in data.columns]
                })
                st.dataframe(tipos_dados, use_container_width=True)
            
            with col2:
                st.subheader("Primeiras 10 Linhas")
                st.dataframe(data.head(10), use_container_width=True)
                
                if numeric_cols:
                    st.subheader("Estat√≠sticas Descritivas")
                    st.dataframe(data[numeric_cols].describe(), use_container_width=True)
        
        with tab2:
            create_distribution_plots(data, numeric_cols, categorical_cols)
        
        with tab3:
            st.header("üîç Correla√ß√µes entre Vari√°veis")
            
            if len(numeric_cols) > 1:
                # Matriz de correla√ß√£o detalhada
                correlation_matrix = data[numeric_cols].corr()
                
                fig, ax = plt.subplots(figsize=(14, 12))
                fig.patch.set_facecolor('#0E1117')
                
                # Usar colormap com bom contraste
                mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))
                sns.heatmap(correlation_matrix, 
                           mask=mask,
                           annot=True, 
                           cmap='RdYlBu_r', 
                           center=0,
                           square=True,
                           fmt='.3f',
                           cbar_kws={'shrink': 0.8},
                           ax=ax)
                
                ax.set_title('Matriz de Correla√ß√£o (Tri√¢ngulo Superior)', color='white', fontsize=16, pad=20)
                ax.set_facecolor('#0E1117')
                plt.xticks(rotation=45, ha='right', color='white')
                plt.yticks(rotation=0, color='white')
                
                plt.tight_layout()
                st.pyplot(fig)
                plt.close()
                
                # Correla√ß√µes mais fortes
                st.subheader("üéØ Correla√ß√µes Mais Significativas")
                correlations = []
                for i in range(len(correlation_matrix.columns)):
                    for j in range(i+1, len(correlation_matrix.columns)):
                        corr_value = correlation_matrix.iloc[i, j]
                        if abs(corr_value) > 0.1:  # Apenas correla√ß√µes significativas
                            correlations.append({
                                'Vari√°vel 1': correlation_matrix.columns[i],
                                'Vari√°vel 2': correlation_matrix.columns[j],
                                'Correla√ß√£o': corr_value,
                                'Correla√ß√£o Abs': abs(corr_value),
                                'For√ßa': 'Muito Forte' if abs(corr_value) > 0.9 else 'Forte' if abs(corr_value) > 0.7 else 'Moderada' if abs(corr_value) > 0.3 else 'Fraca'
                            })
                
                if correlations:
                    corr_df = pd.DataFrame(correlations).sort_values('Correla√ß√£o Abs', ascending=False)
                    st.dataframe(corr_df[['Vari√°vel 1', 'Vari√°vel 2', 'Correla√ß√£o', 'For√ßa']], use_container_width=True)
                else:
                    st.info("N√£o foram encontradas correla√ß√µes significativas entre as vari√°veis.")
            else:
                st.info("√â necess√°rio ter pelo menos 2 vari√°veis num√©ricas para calcular correla√ß√µes.")
        
        with tab4:
            create_trend_analysis(data, numeric_cols, categorical_cols)
        
        with tab5:
            create_complete_outlier_analysis(data, numeric_cols)
        
        with tab6:
            st.header("ü§ñ Chat Inteligente com Mem√≥ria")
            st.markdown("Converse com a IA sobre seus dados! A IA tem acesso completo aos dados e lembra da conversa.")
            
            # Configura√ß√£o da API
            col1, col2, col3 = st.columns(3)
            
            with col1:
                api_choice = st.selectbox(
                    "üîß Escolha a API:",
                    ["OpenAI", "Groq", "Gemini"],
                    help="Selecione qual API de IA usar"
                )
            
            with col2:
                api_key = st.text_input(
                    f"üîë Chave da API {api_choice}:", 
                    type="password",
                    help="Sua chave ser√° usada apenas para esta sess√£o"
                )
            
            with col3:
                # Modelos por API
                if api_choice == "OpenAI":
                    model_options = ["gpt-3.5-turbo", "gpt-4", "gpt-4-turbo-preview"]
                elif api_choice == "Groq":
                    model_options = ["llama-3.3-70b-versatile", "llama-3.1-8b-instant", "openai/gpt-oss-120b"]
                else:  # Gemini
                    model_options = ["gemini-pro", "gemini-pro-vision"]
                
                selected_model = st.selectbox("üß† Modelo:", model_options)
            
            # Mostrar hist√≥rico de conversa√ß√£o
            if st.session_state.conversation_history:
                st.subheader("üí¨ Hist√≥rico da Conversa")
                for msg in st.session_state.conversation_history[-10:]:  # √öltimas 10 mensagens
                    if msg["role"] == "user":
                        st.markdown(f"**üë§ Voc√™:** {msg['content']}")
                    else:
                        st.markdown(f"**ü§ñ IA:** {msg['content']}")
                st.markdown("---")
            
            # Input para nova pergunta
            user_question = st.text_area(
                "üí≠ Fa√ßa uma pergunta sobre seus dados:",
                placeholder="Exemplo: Quais s√£o os principais insights deste dataset? Existe alguma correla√ß√£o interessante? Quais outliers s√£o mais preocupantes?",
                height=100,
                key="user_input"
            )
            
            col1, col2, col3 = st.columns([1, 1, 2])
            with col1:
                if st.button("üöÄ Enviar Pergunta", type="primary"):
                    if user_question.strip() and api_key:
                        # Adicionar pergunta ao hist√≥rico
                        add_to_conversation("user", user_question)
                        
                        with st.spinner(f"ü§ñ Processando com {api_choice}..."):
                            # Preparar contexto completo
                            context_prompt = f"""
                            Voc√™ √© um especialista em an√°lise de dados. Voc√™ tem acesso completo aos seguintes dados:
                            
                            INFORMA√á√ïES DO DATASET:
                            - Formato: {st.session_state.data_context['shape'][0]} linhas x {st.session_state.data_context['shape'][1]} colunas
                            - Colunas: {', '.join(st.session_state.data_context['columns'])}
                            - Colunas num√©ricas: {', '.join(st.session_state.data_context['numeric_columns'])}
                            - Colunas categ√≥ricas: {', '.join(st.session_state.data_context['categorical_columns'])}
                            
                            ESTAT√çSTICAS B√ÅSICAS:
                            {str(st.session_state.data_context['basic_stats'])}
                            
                            VALORES AUSENTES:
                            {str(st.session_state.data_context['missing_values'])}
                            
                            AMOSTRA DOS DADOS:
                            {str(st.session_state.data_context['sample_data'])}
                            
                            ESTAT√çSTICAS CATEG√ìRICAS:
                            {str(st.session_state.data_context['categorical_stats'])}
                            
                            Responda de forma detalhada e t√©cnica, mas acess√≠vel. Use os dados reais para fundamentar suas respostas.
                            """
                            
                            # Preparar mensagens incluindo hist√≥rico
                            messages = [{"role": "system", "content": context_prompt}]
                            
                            # Adicionar hist√≥rico recente (√∫ltimas 6 mensagens para n√£o exceder limite)
                            recent_history = st.session_state.conversation_history[-6:]
                            for msg in recent_history:
                                messages.append(msg)
                            
                            # Chamar API
                            response = call_ai_api(api_choice, api_key, messages, selected_model)
                            
                            # Adicionar resposta ao hist√≥rico
                            add_to_conversation("assistant", response)
                            
                            # Mostrar resposta
                            st.success("‚úÖ Resposta recebida!")
                            st.markdown("### üéØ Resposta da IA:")
                            st.markdown(response)
                    
                    elif not api_key:
                        st.error("‚ùå Por favor, insira sua chave da API.")
                    else:
                        st.error("‚ùå Por favor, digite uma pergunta.")
            
            with col2:
                if st.button("üóëÔ∏è Limpar Chat"):
                    st.session_state.conversation_history = []
                    st.rerun()
            
            with col3:
                st.markdown("**üí° Dicas de perguntas:**")
                st.markdown("‚Ä¢ Quais s√£o os principais insights?")
                st.markdown("‚Ä¢ Existem padr√µes interessantes?")
                st.markdown("‚Ä¢ Como interpretar os outliers?")
                st.markdown("‚Ä¢ Que an√°lises adicionais recomendar?")
            
            # Instru√ß√µes para obter chaves das APIs
            if not api_key:
                st.info(f"üîë Insira sua chave da API {api_choice} para usar o chat inteligente.")
                
                if api_choice == "OpenAI":
                    st.markdown("""
                    **Como obter chave OpenAI:**
                    1. Acesse [platform.openai.com](https://platform.openai.com)
                    2. Fa√ßa login ‚Üí API Keys ‚Üí Create new key
                    """)
                elif api_choice == "Groq":
                    st.markdown("""
                    **Como obter chave Groq:**
                    1. Acesse [console.groq.com](https://console.groq.com)
                    2. Crie conta gratuita ‚Üí API Keys ‚Üí Create API Key
                    """)
                else:  # Gemini
                    st.markdown("""
                    **Como obter chave Gemini:**
                    1. Acesse [makersuite.google.com](https://makersuite.google.com)
                    2. Get API Key ‚Üí Create API Key
                    """)
    
    except Exception as e:
        st.error(f"‚ùå Erro ao carregar o arquivo: {str(e)}")
        st.info("Verifique se o arquivo est√° no formato CSV correto.")

else:
    # P√°gina inicial
    st.markdown("""
    ## üéØ Bem-vindo ao Agente de An√°lise de Dados MELHORADO!
    
    ### üöÄ Principais Melhorias:
    
    **üß† Chat Inteligente com Mem√≥ria**
    - Conversa√ß√£o cont√≠nua que lembra do contexto
    - Acesso completo aos dados carregados
    - Suporte para OpenAI, Groq e Gemini
    
    **üìä Visualiza√ß√µes Completas**
    - Todas as distribui√ß√µes (num√©ricas e categ√≥ricas)
    - Gr√°ficos de densidade e estat√≠sticas
    - An√°lise completa de outliers
    
    **üìà An√°lise de Tend√™ncias Avan√ßada**
    - Linhas de tend√™ncia autom√°ticas
    - M√©dias m√≥veis
    - Correla√ß√µes visuais
    
    **‚ö†Ô∏è Detec√ß√£o Completa de Outliers**
    - M√©todos IQR e Z-score
    - Visualiza√ß√µes para todas as vari√°veis
    - An√°lise multivariada
    
    ### üì§ Como usar:
    1. **Carregue** seu arquivo CSV
    2. **Explore** as an√°lises autom√°ticas
    3. **Converse** com a IA sobre seus dados
    4. **Obtenha insights** personalizados
    
    **üí° A IA tem acesso completo aos seus dados e pode responder qualquer pergunta sobre eles!**
    """)
